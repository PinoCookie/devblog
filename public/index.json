[{"content":"\rIntroduction\rFor my first project in the \u0026ldquo;Quant AI\u0026rdquo; space I started with one of the easier, but still somewhat challenging project of making a Black-Litterman model that would be able to show the best possible stock allocation based on the market data of the last few years.\nLaying the ground work\rAt first I started of the project getting back into the feeling of using python for data science purposes, since because of my previous study major I did not use python for this goal as much. Because of this I build the project step-by-step\nMethodology\rBlack-Litterman\rThe main part of this project for me was understanding the Black-Litterman model itself.\n$$ E(R) = \\left[ (\\tau \\Sigma)^{-1} + P^{T} \\Omega^{-1} P \\right]^{-1} \\left[ (\\tau \\Sigma)^{-1} \\Pi + P^{T} \\Omega^{-1} Q \\right] $$Where:\n\\( E(R) \\): \\(N \\times 1\\) vector of posterior expected returns (number of assets = \\(N\\)) \\( Q \\): \\(K \\times 1\\) vector of views \\( P \\): \\(K \\times N\\) picking matrix mapping views to assets \\( \\Omega \\): \\(K \\times K\\) diagonal covariance (uncertainty) matrix of views \\( \\Pi \\): \\(N \\times 1\\) vector of prior (equilibrium) expected returns \\( \\Sigma \\): \\(N \\times N\\) covariance matrix of asset returns \\( \\tau \\): scalar tuning constant (reflecting uncertainty in the prior) This gives us a good starting point for the code.\nPython\rFor this project we will be making use of the PyPortfolioOpt\rmodule, this module will make the overal calculations a lot easier.\nfrom pypfopt import black_litterman, risk_models from pypfopt import BlackLittermanModel, plotting from pypfopt import EfficientFrontier, objective_functions Then for the data I used the yfinance\rmodule, this module gives me easy access to all the market data based on tickers. As of tickers I choose:\nimport yfinance as yf As of tickers I choose\ntickers = [\u0026#34;MSFT\u0026#34;, \u0026#34;AMZN\u0026#34;, \u0026#34;NVDA\u0026#34;, \u0026#34;LLY\u0026#34;, \u0026#34;AVGO\u0026#34;, \u0026#34;PLTR\u0026#34;, \u0026#34;GE\u0026#34;, \u0026#34;STX\u0026#34;, \u0026#34;HWM\u0026#34;, \u0026#34;UNP\u0026#34;, \u0026#34;MA\u0026#34;, \u0026#34;V\u0026#34;, \u0026#34;ADP\u0026#34;, \u0026#34;DE\u0026#34;, \u0026#34;LMT\u0026#34;] From this I retrieved the data and filtered the data to training data (up until this year) and test data (this year)\ndata = yf.download(tickers + [\u0026#39;SPY\u0026#39;], period=\u0026#34;3y\u0026#34;)[\u0026#39;Close\u0026#39;] current_year_mask = pd.to_datetime(data.index) \u0026gt; pd.to_datetime(\u0026#39;2024-12-31\u0026#39;) training_data = data[~current_year_mask].loc[:, data.columns != \u0026#39;SPY\u0026#39;] training_market_prices = data[~current_year_mask][\u0026#39;SPY\u0026#39;] current_year_data = data[current_year_mask].loc[:, data.columns != \u0026#39;SPY\u0026#39;] current_year_spy = data[current_year_mask][\u0026#39;SPY\u0026#39;] Now we can start calculating, the first caluclation we will do is find the covariance matrix for the stocks that we choose.\nS = risk_models.CovarianceShrinkage(training_data).ledoit_wolf() The variance matrix we will shrink using Ledoit and Wolf proposed method in \u0026ldquo;A well-conditioned estimator for large-dimensional covariance matrices\u0026rdquo;\rAfter this we start calculating the market priors.\ndelta = black_litterman.market_implied_risk_aversion(training_market_prices) market_prior = black_litterman.market_implied_prior_returns(ticker_market_caps, delta, S) Then the P Q and confidence levels\nai_stocks = [0,1,2,4,5,7] q = np.array([0.10]).reshape(-1,1) p = np.array( [[1/6,1/6,1/6,-1/9,1/6,1/6,-1/9,1/6,-1/9,-1/9,-1/9,-1/9,-1/9,-1/9,-1/9]] ) confidences = [0.4] For this I used the current hype around AI stocks.\nWith this we were able to calculate the stock allocation proposed by the model\nef = EfficientFrontier(post_returns_bl, bl.bl_cov()) ef.add_objective(objective_functions.L2_reg) ef.max_sharpe() weights = ef.clean_weights() weights pd.Series(weights).plot.pie(figsize=(10,10)); After this doing some backtesting of the S\u0026amp;P 500 (SPY) and my own portifolio, I got these results With a sharpe ratio of \u0026hellip;\nResults\rFrom this I can conclude that the first phase of the project was definetly a success, the model was able to outperform the S\u0026amp;P 500 with quite the amount. This does not mean that everyone should now invest in the portfolio I calculated, because my personal views were heavily based on what I know this year brought. But it does show the impact of being able to add your own views into the mix when determining how to allocate your portfolio.\nEverything needs AI\rNow that the manual work has been done and I have an understanding of the subject, I wanted to add AI into the mix and let them compete against one another to see who would be able to best predict the market.\nMethodology\rThis part of the project took by far the longest, this was because I needed to find out how to get AI\u0026rsquo;s to behave in the exact way that I want and return me the information I was looking for. At the current stage of AI this is still quite the ask to make. So for this I created a python module to help me out with some of the parts. In this model I build 3 tools for the AI\u0026rsquo;s to use while trying to come up with an answer. These tools consisted of a search engine, this engine was a locally hosted searchxng container which they were able to access through a query. Then I gave them access to the previously mentioned yfinance module, through this they were able to get market information on by them requested stocks, and lastely a P and Q validation tool. This tool was added later into the development, because I kept bumping my head into the problem that the AI\u0026rsquo;s were struggling with formulating these variables correctly.\nResults\rThis time I will not bore you with all the little steps but immediatly show you the results of the great AI Stock trading portfolio allocation competition\u0026hellip;.\nFirst of their allocations.\nAnd now the backtesting results.\nWith sharpe ratios of:\n------------------------------------------------------- Model Return Sharpe Ratio ------------------------------------------------------- GPT-5 mini 37.88% 1.14 Qwen3 25.32% 0.82 Grok 4.1 fast 33.45% 0.96 ------------------------------------------------------- S\u0026amp;P 500 18.09% 0.86 So in the end not that promissing\u0026hellip;\nDiscussions\r","date":"December 4, 2025","permalink":"/posts/black-litterman-model/","summary":"\rIntroduction\rFor my first project in the \u0026ldquo;Quant AI\u0026rdquo; space I started with one of the easier, but still somewhat challenging project of making a Black-Litterman model that would be able to show the best possible stock allocation based on the market data of the last few years.\n","title":"Black Litterman Model","type":"posts"}]